from typing import List, Optional
from openai import OpenAI
import os
from dotenv import load_dotenv
from backend.types import TaskMetadata, TaskJudgment

# Load environment variables from .env file
load_dotenv()

# --- Constants ---
DEFAULT_MODEL = "gpt-4"

# --- Shared LLM client accessor ---
def get_client():
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key:
        raise ValueError(
            "OpenAI API key not found. Please set the OPENAI_API_KEY environment variable. "
            "You can get an API key from https://platform.openai.com/api-keys"
        )
    return OpenAI(api_key=openai_api_key)

# --- LLM-enabled functions ---
def extract_task(state) -> TaskMetadata:
    """
    Use LLM to extract the main task, assess confidence, raise concerns, and generate clarifying questions.
    """
    client = get_client()

    system_msg = (
        "You are an expert task manager assistant."
        " Given a user request, extract the main task, assess how confident you are in your interpretation,"
        " list any concerns or ambiguities, and write any clarification questions you'd ask the user before proceeding."
    )

    user_prompt = f"""
    USER REQUEST:
    {state.input}

    Respond in this JSON format:
    {{
      "task": <string>,
      "confidence": <float 0-1>,
      "concerns": [<string>...],
      "questions": [<string>...]
    }}
    """

    response = client.chat.completions.create(
        model=DEFAULT_MODEL,
        messages=[
            {"role": "system", "content": system_msg},
            {"role": "user", "content": user_prompt}
        ]
    )

    import json
    try:
        content = response.choices[0].message.content.strip()
        return TaskMetadata(**json.loads(content))
    except Exception as e:
        return TaskMetadata(
            task=state.input.strip(),
            confidence=0.5,
            concerns=["Failed to parse LLM response"],
            questions=[]
        )

def clarify(missing_info: List[str]) -> dict:
    """
    Generate clarification questions for missing task info using an LLM.
    """
    client = get_client()
    if not missing_info:
        return {"questions": []}

    prompt = f"""
    A task is missing the following pieces of information: {', '.join(missing_info)}.
    Write a short clarification question for each.
    """
    response = client.chat.completions.create(
        model=DEFAULT_MODEL,
        messages=[
            {"role": "system", "content": "You generate clarification questions for missing task details."},
            {"role": "user", "content": prompt}
        ]
    )
    content = response.choices[0].message.content.strip()
    questions = [line.lstrip("- ").strip() for line in content.splitlines() if line.strip()]
    return {
        "questions": questions
    }

def review(task: str, subtasks: Optional[List[str]] = None) -> dict:
    """
    Present the task and subtasks back to the user for review.
    """
    return {
        "task": task,
        "subtasks": subtasks or [],
        "message": "Here's what I've extracted. Let me know if you'd like to change anything."
    }

def revise_subtasks(user_feedback: str, subtasks: List[str]) -> dict:
    """
    Accept user feedback and modify subtasks using an LLM.
    """
    client = get_client()
    prompt = f"""
    Current subtasks:
    {chr(10).join(f"- {s}" for s in subtasks)}

    User feedback:
    "{user_feedback}"

    Please return an updated list of subtasks based on the feedback.
    Return them as a plain numbered list.
    """
    response = client.chat.completions.create(
        model=DEFAULT_MODEL,
        messages=[
            {"role": "system", "content": "You are a helpful assistant that revises task subtasks."},
            {"role": "user", "content": prompt}
        ]
    )
    content = response.choices[0].message.content.strip()
    new_subtasks = [line.split(".", 1)[-1].strip(" ") for line in content.splitlines() if line.strip()]
    return {
        "subtasks": new_subtasks
    }

def judge_task(metadata: TaskMetadata) -> TaskJudgment:
    """
    Determine if the extracted task is clearly defined and actionable.
    Uses task confidence, concerns, and clarification questions as context.
    """
    client = get_client()

    system_msg = (
        "You are a quality control specialist reviewing a proposed task generated by an AI assistant."
        " Determine if the task is clearly actionable, unambiguous, and properly scoped."
        " If it is not, return a 'fail' judgment and suggest what the assistant should clarify."
    )

    user_prompt = f"""
    Task: {metadata.task}
    Confidence Score: {metadata.confidence}

    Concerns:
    {chr(10).join(metadata.concerns) if metadata.concerns else 'None'}

    Clarification Questions:
    {chr(10).join(metadata.questions) if metadata.questions else 'None'}

    Respond in this format:
    {{
      "judgment": "pass" or "fail",
      "reason": "<optional explanation>"
    }}
    """

    response = client.chat.completions.create(
        model=DEFAULT_MODEL,
        messages=[
            {"role": "system", "content": system_msg},
            {"role": "user", "content": user_prompt}
        ]
    )

    import json
    try:
        content = response.choices[0].message.content.strip()
        return TaskJudgment(**json.loads(content))
    except Exception:
        return TaskJudgment(
            judgment="fail",
            reason="Task judgment failed: unable to parse LLM response."
        )

def judge_subtasks(original_prompt: str, final_task: str, subtasks: List[str]) -> dict:
    """
    Check if the subtasks are a reasonable decomposition of the original task.
    """
    client = get_client()
    prompt = f"""
    Original task input:
    "{original_prompt}"

    Extracted main task:
    "{final_task}"

    Proposed subtasks:
    {chr(10).join(f"- {s}" for s in subtasks)}

    Are the subtasks a reasonable breakdown of the task? Respond with "approved" or "needs revision" only.
    """
    response = client.chat.completions.create(
        model=DEFAULT_MODEL,
        messages=[
            {"role": "system", "content": "You are an expert task workflow judge."},
            {"role": "user", "content": prompt}
        ]
    )
    result = response.choices[0].message.content.strip().lower()
    return {
        "status": "approved" if "approved" in result else "needs revision"
    }

def save_task_to_db(task: str, subtasks: Optional[List[str]] = None):
    subtasks = subtasks or []
    print(f"[SAVE] Task: {task}\n[SUBTASKS]\n" + chr(10).join(f"- {s}" for s in subtasks))
    return {
        "status": "saved"
    }

def generate_subtasks(task: str) -> dict:
    """
    Generate subtasks for a given task. Currently a stub.
    TODO: Implement LLM-based subtask generation
    """
    return {
        "subtasks": ["Subtask 1", "Subtask 2"],  # Placeholder subtasks
        "missing_info": []  # Placeholder missing info
    }

def ask_clarifying_questions(questions: List[str]) -> dict:
    """
    Present clarifying questions to the user. Currently a stub.
    TODO: Implement UI interaction for asking questions
    """
    return {
        "updated_input": "User's response to questions"  # Placeholder response
    }

def create_task(task: str, subtasks: Optional[List[str]] = None) -> dict:
    """
    Create a new task with optional subtasks. Currently a stub.
    TODO: Implement task creation logic
    """
    return {
        "status": "created",
        "task": task,
        "subtasks": subtasks or []
    }

# The following functions are stubs for the v2 task agent
def ask_to_subtask(task: str) -> dict:
    """
    Ask the user to select a subtask from a list.
    """
    return {
        "decision": "no"
    }
def create_clarifying_questions(task: str) -> dict:    
    """
    Create clarifying questions for a subtask.
    """
    return {
        "questions": [f"What is the purpose of {subtask}?" for subtask in subtasks]
    }
def receive_clarification_feedback(feedback: str, subtask: str) -> dict:
    """
    Receive feedback on a clarification question.
    """
    return {
        "feedback": feedback
    }
